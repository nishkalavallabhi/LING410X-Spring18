titleline <- moby.chap.positions[i]
title <- moby.actual[titleline]
start <- titleline+1
end   <- moby.chap.positions[i+1]-1
chapter.lines <- moby.actual[start:end]
chapter.string <- tolower(paste(chapter.lines, collapse = " "))
chapter.string <- gsub(" +", " ", gsub("[[:punct:]]", " ", chapter.string))
chapter.words <- unlist(strsplit(chapter.string, "\\W"))
chapter.freqs <- table(chapter.words)
chapters.raw[[title]] <- chapter.freqs
}
chapters.raw[[1]]
sum(chapters.raw[[1]])
length(chapers[[1]])
length(chapters.raw[[1]])
sum_of_all_word_freqs_chapter1 <- sum(chapters_raw[[1]])
num_words_in_chapter1 <- length(chapters_raw[[1]])
mean_word_freq_chapter1 <- sum_of_all_word_freqs_chapter1/num_words_in_chapter1
sum_of_all_word_freqs_chapter1 <- sum(chapters.raw[[1]])
num_words_in_chapter1 <- length(chapters.raw[[1]])
mean_word_freq_chapter1 <- sum_of_all_word_freqs_chapter1/num_words_in_chapter1
mean_word_freq_chapter1
mean(chapters.raw[[1]])
lapply(chapters.raw, "[[")
lapply(chapters.raw, "[")
?sapply
lapply(chapters.raw, mean)
lapply(chapters.raw, mean)
length(chapters.raw)
means = c()
for(i in 1:length(chapters.raw))
{
means[i] <- sum(chapters.raw[[i]])/length(chapters.raw)
}
means
means = c()
for(i in 1:length(chapters.raw))
{
means[i] <- sum(chapters.raw[[i]])/length(chapters.raw[[i]])
}
means
matrix(lapply(chapters.raw,mean))
vector(lapply(chapters.raw,mean))
?rbind
rbind(lapply(chapters.raw, mean))
?lapply
sapply(chapters.raw, mean)
trial <- sapply(chapters.raw, mean)
class(trial)
typeof(trial)
trial <- sapply(chapters.raw, mean, simplify="vector")
trial
trial[[1]]
trial[[2]]
plot(trial)
trial <- sapply(chapters.raw, mean)
trial <- lapply(chapters.raw, mean)
plot(trial)
trial <- sapply(chapters.raw, mean)
trial <- lapply(chapters.raw, mean)
trial
typeof(trial)
unname(trial)
unlist(unname(trial))
trial <- lapply(chapters.raw, mean)
unlist(trial)
trial <- lapply(chapters.raw, mean)
unlist(trial)
unname(unlist(trial))
means <- lapply(chapters.raw, mean)
means <- unlist(means)
means <- unname(means)
means
par(mfrow=c(1,2))
plot(means, type="h")
plot(scale(means), type = "h")
means <- lapply(chapters.raw, mean)
sort(means)
means <- unlist(means)
sort(means)
sort(means, decreasing=TRUE)
hapax <- sapply(chapters.raw, function(x) sum(x == 1))
hapax
unname(hapax)
unlist(hapax)
unname(hapax)
lapply(chapters.raw,length)
lapply(chapters.raw,sum)
hapax <- sapply(chapters.raw, function(x) sum(x == 1))
hapax <- unname(hapax)
lengths <- lapply(chapters.raw, sum)
new <- hapax/lengths
lengths
hapax <- sapply(chapters.raw, function(x) sum(x == 1))
hapax <- unname(hapax)
lengths <- lapply(chapters.raw, sum)
new <- hapax/lengths
hapax <- sapply(chapters.raw, function(x) sum(x == 1))
hapax <- unname(hapax)
lengths <- unname(sapply(chapters.raw, sum))
new <- hapax/lengths
new
?par
hapax <- sapply(chapters.raw, function(x) sum(x == 1:5))
hapax
moby <- scan("mobydick.txt", what = "character", sep = "\n")
moby.start <- which (moby ==  "CHAPTER 1. Loomings.")
moby.end <- which (moby == "orphan.")
moby.actual <- moby[moby.start:moby.end]
moby <- scan("mobydick.txt", what = "character", sep = "\n")
moby.start <- which (moby ==  "CHAPTER 1. Loomings.")
moby.end <- which (moby == "orphan.")
moby.actual <- moby[moby.start:moby.end]
moby.actual <- tolower(paste(moby.actual, collapse = " "))
moby.actual <- gsub(" +", " ", gsub("[[:punct:]]", " ", moby.actual)
moby.words <- unlist(strsplit(moby.actual, "\\W"))
moby.freqs <- table(moby.words)
moby <- scan("mobydick.txt", what = "character", sep = "\n")
moby.start <- which (moby ==  "CHAPTER 1. Loomings.")
moby.end <- which (moby == "orphan.")
moby.actual <- moby[moby.start:moby.end]
moby.actual <- tolower(paste(moby.actual, collapse = " "))
moby.actual <- gsub(" +", " ", gsub("[[:punct:]]", " ", moby.actual)
)
moby.words <- unlist(strsplit(moby.actual, "\\W"))
moby.freqs <- table(moby.words)
moby.freqs
max_freq <- sort(moby.freqs, decreasing = TRUE)
max_freq <- sort(moby.freqs, decreasing = TRUE)[1]
max_freq
max_freq <- sort(moby.freqs, decreasing = TRUE)[[1]]
max_freq
what_i_want <- c()
for(i in min_freq:max_freq)
{
what_i_want[i] <- length(sapply(moby.freqs, function(x) x==i))
}
what_i_want
min_freq <- 1
what_i_want <- c()
for(i in min_freq:max_freq)
{
what_i_want[i] <- length(sapply(moby.freqs, function(x) x==i))
}
min_freq <- 1
what_i_want <- c()
for(i in min_freq:100)
{
what_i_want[i] <- length(sapply(moby.freqs, function(x) x==i))
}
what_i_want
what_i_want <- c()
for(i in min_freq:100)
{
what_i_want[i] <- length(sapply(moby.freqs, function(x) sum(x==i)))
}
what_i_want
moby.freqs
max_freq
sapply(moby.freqs, function(x) sum(x)==1)
max_freq
sapply(moby.freqs, function(x) sum(x)==14715)
length(sapply(moby.freqs, function(x) sum(x)==14715))
sapply(moby.freqs, function(x) sum(x)==14715)
sapply(moby.freqs, function(x) sum(x)==14715)["TRUE"]
length(which(sapply(moby.freqs, function(x) sum(x)==14715))
)
length(which(sapply(moby.freqs, function(x) sum(x)==1))
)
length(which(sapply(moby.freqs, function(x) sum(x)==1)))
max_freq
length(which(sapply(moby.freqs, function(x) sum(x)==14175)))
for(i in min_freq:100)
{
what_i_want[i] <- length(which(sapply(moby.freqs, function(x) sum(x)==14175)))
}
plot(what_i_want)
for(i in min_freq:100)
{
what_i_want[i] <- length(which(sapply(moby.freqs, function(x) sum(x)==i)))
}
plot(what_i_want)
plot(unname(sort(moby.freqs, decreasing = TRUE)))
plot(moby.freqs)
freqslist <- unname(sort(moby.freqs, decreasing = TRUE))
freqslist
plot(freqslist, type="b")
plot(freqslist)
plot(unlist(freqslist))
typeof(freqslist)
freqslist <- sort(moby.freqs, decreasing = TRUE)
freqslist <- unlist(sort(moby.freqs, decreasing = TRUE))
freqslist
length(moby.freqs)
length(freqslist)
vec <- unname(freqslist)
typeof(vec)
class(vec)
plot(vec)
class(freqslist)
library(mallet)
install.packages("rJava")
R
quit()
library("rJava")
library("mallet")
quit()
library(stylo)
mycsvfile[1:3]
file_path = "/home/bangaru/Dropbox/ClassroomSlides-BothCourses/LING410X/Resources/20Apr2017/twitter-sentiment.csv"
mycsvfile = read.csv(file_path, head=TRUE)
colnames(mycsvfile)
#This gives you column names in the csv file. You can choose the column name you want by using $ sign.
#mycsvfile$ItemID #Gives you the entire column.
#mycsvfile[,1] #Also does the same thing because that is the first column.
#mycsvfile[1,] #Gives you the first ROW of this file after the header.
mycsvfile[1:3]
mycsvfile[,1:3]
library(GuardianR)
results <- get_guardian("united+states", section="world", from.date="2014-09-16", to.date="2014-09-16", api.key="8b40468e-139b-4d90-94ac-1f74d22fd291")
names(results)
nrow(results)
ncol(results)
resutls1]
resutls[1]
resutls["1"]
results[1]
results[2]
library(ngram)
text = "Trying this out right now to see see it see to see"
unigrams <- ngram(text, n=2)
unigrams
head(get.phrasetable(unigrams),n = 6)
install.packages("swirl")
library(swirl)
swirl()
1:20
pi:10
15:1
?:
?`:`
seq(1,20)
seq(0,10,by=0.5)
seq(5,10,length=30)
my_seq <- seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
rep(0,times=40)
rep(c(0,1,2),times=10)
rep(c(0,1,2), each=10)
3+4
c = "Sowmya"
c
install.packages("swirl")
library(swirl)
swirl()
5+7
?abs
?paste
5+7
x ,-5 + 7
x <-5 + 7
0
0
x
quit()
list4 <- list(first="Sowmya", course=410, office=331, address="Ross")
list4[1]
list4[[1]]
library(rtimes)
Sys.setenv(NYTIMES_AS_KEY = "c67c9de54f894135ac568dda4f7679ee")
res1 <- as_search(q="artificial intelligence", begin_date = "20081001", end_date = "20081201")
res1$data$snippet
res1
res1$data
res1$data$Snippet
res1$data["Snippet"]
names(res1$data)
res1
names(res1)
names(res1$data)
res1$data
res1$data[[1]]
install.packages("rtimes")
Sys.setenv(NYTIMES_AS_KEY = "c67c9de54f894135ac568dda4f7679ee")
library(rtimes)
res1 <- as_search(q="artificial intelligence", begin_date = "20081001", end_date = "20081201")
names(res1)
res1$data
namse(res1$data)
names(res1$data)
list4 <- list(first="Sowmya", course=410, office=331, address="Ross")
vector4 <- c(first="Sowmya", course=410, office=331, address="Ross")
names(list4)
names(vector4)
vector4["course"]
list4
list4[1]
list4[[1]]
is.list(vector4)
is.vector(vector4)
library(rtimes)
Sys.setenv(NYTIMES_AS_KEY = "c67c9de54f894135ac568dda4f7679ee")
res1 <- as_search(q="artificial intelligence", begin_date = "20081001", end_date = "20081201")
res1
names(res1)
res1$data
names(res1$data)
res1$data$web_url
res1$data$snippet
snippets_2008 <-  res1$data$snippet
for (snippet in snippets_2008) {
print(tolower(snippet))
}
df <- data.frame(res1$data$snippet,res1$data$pub_date)
write.csv(df,"temp.csv")
getwd()
setwd("~/Desktop/Teaching@ISU/SPRING18/LING410X/Assignments/Assignment5/A5-Corpus")
setwd("~/Desktop/Teaching@ISU/SPRING18/LING410X/Assignments/Assignment5/A5-Corpus")
library(tm)
install.packages("topicmodels")
install.packages("topicmodels")
library(topicmodels)
filenames <- list.files(getwd(),pattern="*.txt")
files <- lapply(filenames,readLines)
docs <- Corpus(VectorSource(files))
my_corpus <- tm_map(docs, content_transformer(tolower),lazy=TRUE)
my_corpus <- tm_map(my_corpus, removeWords, stopwords("english"), lazy=TRUE)
my_corpus <- tm_map(my_corpus, removeNumbers, lazy=TRUE)
my_corpus <- tm_map(my_corpus, removePunctuation, lazy=TRUE)
my_corpus <- tm_map(my_corpus, stripWhitespace, lazy=TRUE)
my_corpus <- tm_map(my_corpus, stemDocument, lazy=TRUE)
my_corpus <- tm_map(docs, content_transformer(tolower),lazy=TRUE)
my_corpus <- tm_map(docs, content_transformer(tolower))
my_corpus <- tm_map(docs, content_transformer(tolower))#,lazy=TRUE)
my_corpus <- tm_map(my_corpus, removeWords, stopwords("english"))#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, removeNumbers)#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, removePunctuation)#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, stripWhitespace)#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, stemDocument)#, lazy=TRUE) #Is it needed? Why?
my_corpus <- tm_map(my_corpus, PlainTextDocument)
myDtm <- DocumentTermMatrix(my_corpus)
rownames(myDtm) <- filenames
nrow(myDtm)
length(docs)
length(mycorpus)
length(my_corpus)
docs <- Corpus(VectorSource(files))
my_corpus <- tm_map(docs, content_transformer(tolower))#,lazy=TRUE)
my_corpus <- tm_map(my_corpus, removeWords, stopwords("english"))#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, removeNumbers)#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, removePunctuation)#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, stripWhitespace)#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, stemDocument)#, lazy=TRUE) #Is it needed? Why?
#set your working directory.
#install required libraries: tm, topicmodels
#load required libraries
library("tm")
library("topicmodels")
#get listing of .txt files in directory
filenames <- list.files(getwd(),pattern="*.txt")
#read files into a character vector
files <- lapply(filenames,readLines)
#create corpus from vector using Corpus function in tm
docs <- Corpus(VectorSource(files))
#start preprocessing: Transform to lower case, remove stopwords, remove numbers, punctuation, strip whitespace, do stemming
#lazy=TRUE seems to be required on some operating systems. So, I am putting that in comments - if you need, uncomment that part.
my_corpus <- tm_map(docs, content_transformer(tolower))#,lazy=TRUE)
my_corpus <- tm_map(my_corpus, removeWords, stopwords("english"))#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, removeNumbers)#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, removePunctuation)#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, stripWhitespace)#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, stemDocument)#, lazy=TRUE) #Is it needed? Why?
#The following statement is to avoid Error in UseMethod("meta", x) : no applicable method for 'meta' applied to an object of class "try-error"
#my_corpus <- tm_map(my_corpus, content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')), mc.cores=1, lazy=TRUE)
my_corpus <- tm_map(my_corpus, PlainTextDocument)
#Create document-term matrix
myDtm <- DocumentTermMatrix(my_corpus)
#convert rownames to filenames
rownames(myDtm) <- filenames
my_corpus <- tm_map(my_corpus, PlainTextDocument)
my_corpus <- tm_map(docs, content_transformer(tolower))#,lazy=TRUE)
my_corpus <- tm_map(my_corpus, removeWords, stopwords("english"))#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, removeNumbers)#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, removePunctuation)#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, stripWhitespace)#, lazy=TRUE)
my_corpus <- tm_map(my_corpus, stemDocument)#, lazy=TRUE) #Is it needed? Why?
myDtm <- DocumentTermMatrix(my_corpus)
rownames(myDtm) <- filenames
freq <- colSums(as.matrix(myDtm))
length(freq)
ord <- order(freq,decreasing=TRUE)
write.csv(freq[ord],"../word_freq.csv")
burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
#number of topics
k <- 5
#Run LDA using Gibbs sampling
ldaOut <-LDA(myDtm,k, method="Gibbs", control=list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
ldaOut.topics <- as.matrix(topics(ldaOut))
write.csv(ldaOut.topics,file=paste("LDAGibbs",k,"DocsToTopics.csv"))
ldaOut.terms <- as.matrix(terms(ldaOut,10))
write.csv(ldaOut.terms,file=paste("LDAGibbs",k,"TopicsToTerms.csv"))
topicProbabilities <- as.data.frame(ldaOut@gamma)
write.csv(topicProbabilities,file=paste("LDAGibbs",k,"TopicProbabilities.csv"))
topic1ToTopic2 <- lapply(1:nrow(myDtm),function(x)
sort(topicProbabilities[x,])[k]/sort(topicProbabilities[x,])[k-1])
topic2ToTopic3 <- lapply(1:nrow(myDtm),function(x)
sort(topicProbabilities[x,])[k-1]/sort(topicProbabilities[x,])[k-2])
write.csv(topic1ToTopic2,file=paste("LDAGibbs",k,"Topic1ToTopic2.csv"))
write.csv(topic2ToTopic3,file=paste("LDAGibbs",k,"Topic2ToTopic3.csv"))
setwd("~/Dropbox/ClassroomSlides-BothCourses/LING410X/Week5Mats/code")
moby <- scan("mobydick.txt", what = "character", sep = "\n")
moby.start <- which (moby ==  "CHAPTER 1. Loomings.")
moby.end <- which (moby == "orphan.")
moby.actual <- moby[moby.start:moby.end]
moby.chap.positions <- grep("^CHAPTER \\d", moby.actual)
moby.actual[moby.chap.positions]
moby.last.position <- length(moby.actual)
moby.chap.positions <- c(moby.chap.positions, moby.last.position)
moby.actual[moby.chap.positions]
chapters.raw <- list()
for (i in 1:(length(moby.chap.positions) -1))
{
titleline <- moby.chap.positions[i]
title <- moby.actual[titleline]
start <- titleline+1
end   <- moby.chap.positions[i+1]-1
chapter.lines <- moby.actual[start:end]
chapter.string <- tolower(paste(chapter.lines, collapse = " "))
chapter.string <- gsub(" +", " ", gsub("[[:punct:]]", " ", chapter.string))
chapter.words <- unlist(strsplit(chapter.string, "\\W"))
chapter.freqs <- table(chapter.words)
chapters.raw[[title]] <- chapter.freqs
}
hapax <- sapply(chapters.raw, function(x) sum(x == 1))
hapax
hapaxfunction <- function(x)
{
return(sum(x ==1))
}
hapax <- sapply(chapters.raw, hapaxfunction)
hapax
hapax <- unname(hapax)
hapax
lengths <- unname(sapply(chapters.raw, sum))
lengths
new <- hapax/lengths
new
which.min(new)
which.max(new)
sum(chapters.raw)
sapply(chapters.raw,sum)
sum(sapply(chapters.raw,sum))
214209/135
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/Week5Mats/code/TextAnalFunctions.R')
setwd("~/Dropbox/ClassroomSlides-BothCourses/LING410X/Week5Mats/code")
dollshousewords <- get_words_vector("DollsHouse-Eng.txt")
dollshousewords
get_dispersion_plot(dollshousewords,"nora")
get_dispersion_plot(dollshousewords,"helmer")
get_dispersion_plot(dollshousewords,"rank")
get_dispersion_plot(dollshousewords,"doll")
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/Week5Mats/code/TextAnalFunctions.R')
get_freq_words(dollshousewords,20)
get_freq_words(dollshousewords,t)
get_freq_words(dollshousewords,5)
moby <- scan("mobydick.txt", what = "character", sep = "\n")
moby.start <- which (moby ==  "CHAPTER 1. Loomings.")
moby.end <- which (moby == "orphan.")
moby.actual <- moby[moby.start:moby.end]
moby.chap.positions <- grep("^CHAPTER \\d", moby.actual)
moby.actual[moby.chap.positions]
moby.last.position <- length(moby.actual)
moby.chap.positions <- c(moby.chap.positions, moby.last.position)
moby.actual[moby.chap.positions]
chapters.raw <- list()
for (i in 1:(length(moby.chap.positions) -1))
{
titleline <- moby.chap.positions[i]
title <- moby.actual[titleline]
start <- titleline+1
end   <- moby.chap.positions[i+1]-1
chapter.lines <- moby.actual[start:end]
chapter.string <- tolower(paste(chapter.lines, collapse = " "))
chapter.string <- gsub(" +", " ", gsub("[[:punct:]]", " ", chapter.string))
chapter.words <- unlist(strsplit(chapter.string, "\\W"))
chapter.freqs <- table(chapter.words)
chapters.raw[[title]] <- chapter.freqs
}
hapaxfunction <- function(x)
{
return(sum(x ==1))
}
hapax <- sapply(chapters.raw, hapaxfunction)
hapax
unname(hapax)
plot(unname(hapax))
lengths <- unname(sapply(chapters.raw, sum)) #What will this have?
hapax <- unname(hapax)
hapax
lengths
hapax/lengths
which.max(hapax/lengths)
which.min(hapax/lengths)
setwd("~/Dropbox/ClassroomSlides-BothCourses/LING410X/Assignment5/A5-Corpus/A5-Corpus")
