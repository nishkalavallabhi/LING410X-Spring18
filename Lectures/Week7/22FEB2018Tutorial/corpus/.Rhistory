{
titleline <- moby.chap.positions[i]
title <- moby.actual[titleline]
start <- titleline+1
end   <- moby.chap.positions[i+1]-1
chapter.lines <- moby.actual[start:end]
chapter.string <- tolower(paste(chapter.lines, collapse = " "))
chapter.string <- gsub(" +", " ", gsub("[[:punct:]]", " ", chapter.string))
chapter.words <- unlist(strsplit(chapter.string, "\\W"))
chapter.freqs <- table(chapter.words)
chapters.raw[[title]] <- chapter.freqs
}
chapters.raw[[1]]
sum(chapters.raw[[1]])
length(chapers[[1]])
length(chapters.raw[[1]])
sum_of_all_word_freqs_chapter1 <- sum(chapters_raw[[1]])
num_words_in_chapter1 <- length(chapters_raw[[1]])
mean_word_freq_chapter1 <- sum_of_all_word_freqs_chapter1/num_words_in_chapter1
sum_of_all_word_freqs_chapter1 <- sum(chapters.raw[[1]])
num_words_in_chapter1 <- length(chapters.raw[[1]])
mean_word_freq_chapter1 <- sum_of_all_word_freqs_chapter1/num_words_in_chapter1
mean_word_freq_chapter1
mean(chapters.raw[[1]])
lapply(chapters.raw, "[[")
lapply(chapters.raw, "[")
?sapply
lapply(chapters.raw, mean)
lapply(chapters.raw, mean)
length(chapters.raw)
means = c()
for(i in 1:length(chapters.raw))
{
means[i] <- sum(chapters.raw[[i]])/length(chapters.raw)
}
means
means = c()
for(i in 1:length(chapters.raw))
{
means[i] <- sum(chapters.raw[[i]])/length(chapters.raw[[i]])
}
means
matrix(lapply(chapters.raw,mean))
vector(lapply(chapters.raw,mean))
?rbind
rbind(lapply(chapters.raw, mean))
?lapply
sapply(chapters.raw, mean)
trial <- sapply(chapters.raw, mean)
class(trial)
typeof(trial)
trial <- sapply(chapters.raw, mean, simplify="vector")
trial
trial[[1]]
trial[[2]]
plot(trial)
trial <- sapply(chapters.raw, mean)
trial <- lapply(chapters.raw, mean)
plot(trial)
trial <- sapply(chapters.raw, mean)
trial <- lapply(chapters.raw, mean)
trial
typeof(trial)
unname(trial)
unlist(unname(trial))
trial <- lapply(chapters.raw, mean)
unlist(trial)
trial <- lapply(chapters.raw, mean)
unlist(trial)
unname(unlist(trial))
means <- lapply(chapters.raw, mean)
means <- unlist(means)
means <- unname(means)
means
par(mfrow=c(1,2))
plot(means, type="h")
plot(scale(means), type = "h")
means <- lapply(chapters.raw, mean)
sort(means)
means <- unlist(means)
sort(means)
sort(means, decreasing=TRUE)
hapax <- sapply(chapters.raw, function(x) sum(x == 1))
hapax
unname(hapax)
unlist(hapax)
unname(hapax)
lapply(chapters.raw,length)
lapply(chapters.raw,sum)
hapax <- sapply(chapters.raw, function(x) sum(x == 1))
hapax <- unname(hapax)
lengths <- lapply(chapters.raw, sum)
new <- hapax/lengths
lengths
hapax <- sapply(chapters.raw, function(x) sum(x == 1))
hapax <- unname(hapax)
lengths <- lapply(chapters.raw, sum)
new <- hapax/lengths
hapax <- sapply(chapters.raw, function(x) sum(x == 1))
hapax <- unname(hapax)
lengths <- unname(sapply(chapters.raw, sum))
new <- hapax/lengths
new
?par
hapax <- sapply(chapters.raw, function(x) sum(x == 1:5))
hapax
moby <- scan("mobydick.txt", what = "character", sep = "\n")
moby.start <- which (moby ==  "CHAPTER 1. Loomings.")
moby.end <- which (moby == "orphan.")
moby.actual <- moby[moby.start:moby.end]
moby <- scan("mobydick.txt", what = "character", sep = "\n")
moby.start <- which (moby ==  "CHAPTER 1. Loomings.")
moby.end <- which (moby == "orphan.")
moby.actual <- moby[moby.start:moby.end]
moby.actual <- tolower(paste(moby.actual, collapse = " "))
moby.actual <- gsub(" +", " ", gsub("[[:punct:]]", " ", moby.actual)
moby.words <- unlist(strsplit(moby.actual, "\\W"))
moby.freqs <- table(moby.words)
moby <- scan("mobydick.txt", what = "character", sep = "\n")
moby.start <- which (moby ==  "CHAPTER 1. Loomings.")
moby.end <- which (moby == "orphan.")
moby.actual <- moby[moby.start:moby.end]
moby.actual <- tolower(paste(moby.actual, collapse = " "))
moby.actual <- gsub(" +", " ", gsub("[[:punct:]]", " ", moby.actual)
)
moby.words <- unlist(strsplit(moby.actual, "\\W"))
moby.freqs <- table(moby.words)
moby.freqs
max_freq <- sort(moby.freqs, decreasing = TRUE)
max_freq <- sort(moby.freqs, decreasing = TRUE)[1]
max_freq
max_freq <- sort(moby.freqs, decreasing = TRUE)[[1]]
max_freq
what_i_want <- c()
for(i in min_freq:max_freq)
{
what_i_want[i] <- length(sapply(moby.freqs, function(x) x==i))
}
what_i_want
min_freq <- 1
what_i_want <- c()
for(i in min_freq:max_freq)
{
what_i_want[i] <- length(sapply(moby.freqs, function(x) x==i))
}
min_freq <- 1
what_i_want <- c()
for(i in min_freq:100)
{
what_i_want[i] <- length(sapply(moby.freqs, function(x) x==i))
}
what_i_want
what_i_want <- c()
for(i in min_freq:100)
{
what_i_want[i] <- length(sapply(moby.freqs, function(x) sum(x==i)))
}
what_i_want
moby.freqs
max_freq
sapply(moby.freqs, function(x) sum(x)==1)
max_freq
sapply(moby.freqs, function(x) sum(x)==14715)
length(sapply(moby.freqs, function(x) sum(x)==14715))
sapply(moby.freqs, function(x) sum(x)==14715)
sapply(moby.freqs, function(x) sum(x)==14715)["TRUE"]
length(which(sapply(moby.freqs, function(x) sum(x)==14715))
)
length(which(sapply(moby.freqs, function(x) sum(x)==1))
)
length(which(sapply(moby.freqs, function(x) sum(x)==1)))
max_freq
length(which(sapply(moby.freqs, function(x) sum(x)==14175)))
for(i in min_freq:100)
{
what_i_want[i] <- length(which(sapply(moby.freqs, function(x) sum(x)==14175)))
}
plot(what_i_want)
for(i in min_freq:100)
{
what_i_want[i] <- length(which(sapply(moby.freqs, function(x) sum(x)==i)))
}
plot(what_i_want)
plot(unname(sort(moby.freqs, decreasing = TRUE)))
plot(moby.freqs)
freqslist <- unname(sort(moby.freqs, decreasing = TRUE))
freqslist
plot(freqslist, type="b")
plot(freqslist)
plot(unlist(freqslist))
typeof(freqslist)
freqslist <- sort(moby.freqs, decreasing = TRUE)
freqslist <- unlist(sort(moby.freqs, decreasing = TRUE))
freqslist
length(moby.freqs)
length(freqslist)
vec <- unname(freqslist)
typeof(vec)
class(vec)
plot(vec)
class(freqslist)
library(mallet)
install.packages("rJava")
R
quit()
library("rJava")
library("mallet")
quit()
library(stylo)
mycsvfile[1:3]
file_path = "/home/bangaru/Dropbox/ClassroomSlides-BothCourses/LING410X/Resources/20Apr2017/twitter-sentiment.csv"
mycsvfile = read.csv(file_path, head=TRUE)
colnames(mycsvfile)
#This gives you column names in the csv file. You can choose the column name you want by using $ sign.
#mycsvfile$ItemID #Gives you the entire column.
#mycsvfile[,1] #Also does the same thing because that is the first column.
#mycsvfile[1,] #Gives you the first ROW of this file after the header.
mycsvfile[1:3]
mycsvfile[,1:3]
library(GuardianR)
results <- get_guardian("united+states", section="world", from.date="2014-09-16", to.date="2014-09-16", api.key="8b40468e-139b-4d90-94ac-1f74d22fd291")
names(results)
nrow(results)
ncol(results)
resutls1]
resutls[1]
resutls["1"]
results[1]
results[2]
library(ngram)
text = "Trying this out right now to see see it see to see"
unigrams <- ngram(text, n=2)
unigrams
head(get.phrasetable(unigrams),n = 6)
install.packages("swirl")
library(swirl)
swirl()
1:20
pi:10
15:1
?:
?`:`
seq(1,20)
seq(0,10,by=0.5)
seq(5,10,length=30)
my_seq <- seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
rep(0,times=40)
rep(c(0,1,2),times=10)
rep(c(0,1,2), each=10)
3+4
c = "Sowmya"
c
install.packages("swirl")
library(swirl)
swirl()
5+7
?abs
?paste
5+7
x ,-5 + 7
x <-5 + 7
0
0
x
quit()
list4 <- list(first="Sowmya", course=410, office=331, address="Ross")
list4[1]
list4[[1]]
library(rtimes)
Sys.setenv(NYTIMES_AS_KEY = "c67c9de54f894135ac568dda4f7679ee")
res1 <- as_search(q="artificial intelligence", begin_date = "20081001", end_date = "20081201")
res1$data$snippet
res1
res1$data
res1$data$Snippet
res1$data["Snippet"]
names(res1$data)
res1
names(res1)
names(res1$data)
res1$data
res1$data[[1]]
install.packages("rtimes")
Sys.setenv(NYTIMES_AS_KEY = "c67c9de54f894135ac568dda4f7679ee")
library(rtimes)
res1 <- as_search(q="artificial intelligence", begin_date = "20081001", end_date = "20081201")
names(res1)
res1$data
namse(res1$data)
names(res1$data)
list4 <- list(first="Sowmya", course=410, office=331, address="Ross")
vector4 <- c(first="Sowmya", course=410, office=331, address="Ross")
names(list4)
names(vector4)
vector4["course"]
list4
list4[1]
list4[[1]]
is.list(vector4)
is.vector(vector4)
library(rtimes)
Sys.setenv(NYTIMES_AS_KEY = "c67c9de54f894135ac568dda4f7679ee")
res1 <- as_search(q="artificial intelligence", begin_date = "20081001", end_date = "20081201")
res1
names(res1)
res1$data
names(res1$data)
res1$data$web_url
res1$data$snippet
snippets_2008 <-  res1$data$snippet
for (snippet in snippets_2008) {
print(tolower(snippet))
}
df <- data.frame(res1$data$snippet,res1$data$pub_date)
write.csv(df,"temp.csv")
getwd()
setwd("~/Dropbox/ClassroomSlides-BothCourses/LING410X/Week6Mats/13-15Feb2018")
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/Week6Mats/13-15Feb2018/KWIC.R')
paste("1st", "2nd", "3rd", collapse = ", ")
paste("1st", "2nd", "3rd", sep = ", ")
paste("1st", "2nd", "3rd", collapse = ", ", sep = ":")
vec1 <- c("1st", "2nd", "3rd")
vec2 <- c("4th", "5th", "6th")
paste(vec1, collapse = ":: ")
paste(vec1, sep = ":: " )
paste(vec1, vec2, sep = "::")
paste(vec1, vec2, sep = "::", collapse = "--")
paste(c('v1', 'v2'), collapes="+")
paste(c('v1', 'v2'), whatever="+")
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/Week6Mats/13-15Feb2018/KWIC.R')
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/Week6Mats/13-15Feb2018/KWIC.R')
library(ngram)
dollshouse_text <- scan("DollsHouse-Eng.txt", what = "character", sep = "\n")
dollshouse_string <- paste(dollshouse_text, collapse = " ")
dollshouse_string <- tolower(dollshouse_string)
dollshouse_string <- gsub("[[:punct:]]", " ", dollshouse_string)
dollshouse_string <- gsub(" +", " ", dollshouse_string)
unigrams <- ngram(dollshouse_string,n=1)
bigrams <- ngram(dollshouse_string,n=2)
trigrams <- ngram(dollshouse_string,n=3)
bigrams_vector <- get.ngrams(bigrams)
trigrams_vector <- get.ngrams(trigrams)
top10unigrams <- head(get.phrasetable(unigrams),n = 10)
top10bigrams <- head(get.phrasetable(bigrams),n = 10)
top10trigrams <- head(get.phrasetable(trigrams),n = 10)
top10unigrams
top10unigrams$freq
plot(top10bigrams$freq,type="b")
typeof(top10bigrams)
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/Week7Mats/lastweek/Ngrams.R', echo=TRUE)
top10unigrams[[2]]
names(top10bigrams)
typeof(top10bigrams$ngrams)
is.vector(top10bigrams$ngrams)
is.list(top10bigrams$ngrams)
setwd("~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/corpus")
setwd("~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/corpus")
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
wordsvector <- get_words_vector("text10.txt")
words_freqs <- table(wordsvector)
sum(words_freqs)
length(words_freqs)
sum(words_freqs==1)
sum(words_freqs==2)
sum(words_freqs>1)
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
get_lex_variety(wordsvector)
result <_ get_lex_variety(wordsvector)
result <- get_lex_variety(wordsvector)
result
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
result <- get_lex_variety(wordsvector)
result
wordsvector <- get_words_vector("temp.txt")
wordsvector
words_freqs(table(wordsvector))
get_lex_variety(wordsvector)
table(wordsvector)
sum(wordsvector==1)
sum(table(wordsvector==1))
sum(table(wordsvector)==1)
vec <- c("This is one")
c
vec
vec <- c(vec, "This is the other")
vec
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
wordsvector <- get_words_vector("text1.txt")
getKwic(wordsvector, "nora", 3)
getKwic(wordsvector, "gutenberg", 3)
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
getKwic(wordsvector, "gutenberg", 3)
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
getKwic(wordsvector, "gutenberg", 3)
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
getKwic(wordsvector, "gutenberg", 3)
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
get_ngrams(wordsvector,3,10)
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
get_ngrams(wordsvector,3,10)
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
get_ngrams(wordsvector,3,10)
text_string <- paste(wordsvector, collapse=" ")
ngrams <- ngram(text_string,n=3)
ngrams
ngrams_vector <- get.ngrams(ngrams)
ngrams_vector
top10ngrams <- head(get.phrasetable(ngrams_vector), n = 10)
top10ngrams <- head(get.phrasetable(ngrams), n = 10)
ngrams_vector
top10ngrams
ngrams_vector
table(ngrams_vector)
top10ngrams
sort(table(ngrams_vector),decreasing = TRUE)[1:10]
sort(table(ngrams_vector))[1:10]
sort(table(ngrams_vector),decreasing = TRUE)
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
get_ngrams(wordsvector,3,10)
final_result <- c("Word is not found in this file.")
final_result
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
get_line_plot(wordsvector,10)
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctions.R')
get_line_plot(wordsvector,10)
file.names <- dir(getwd(), pattern = "\\.txt")
for (f in file.names) {
x <- get_words_vector(f)
print(get_lex_variety(wordsvector))
}
file.names <- dir(getwd(), pattern = "\\.txt")
my_final_vector <- c()
for (f in file.names) {
x <- get_words_vector(f)
my_final_vector <- c(my_final_vector, get_lex_variety(wordsvector))
}
my_final_vector
get_lex_variety(wordsvector)
rbind(get_lex_variety(wordsvector))
rbind(get_lex_variety(wordsvector),get_lex_variety(wordsvector))
file.names <- dir(getwd(), pattern = "\\.txt")
my_final_vector <- c()
for (f in file.names) {
x <- get_words_vector(f)
my_final_vector <- rbind(my_final_vector, get_lex_variety(x))
}
my_final_vector
data.frame(my_final_vector)
write.csv(my_final_vector,"temp.csv")
source('CorpusAnalysisFunctions.R')
file.names <- dir(getwd(), pattern = "\\.txt")
my_final_vector <- c()
for (f in file.names) {
x <- get_words_vector(f)
my_final_vector <- rbind(my_final_vector, get_lex_variety(x))
}
write.csv(my_final_vector,"temp.csv")
source('~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/CorpusAnalysisFunctionsUsage.R', echo=TRUE)
source('CorpusAnalysisFunctions.R')
file.names <- dir(getwd(), pattern = "\\.txt")
my_final_vector <- c()
for (f in file.names) {
x <- get_words_vector(f)
my_final_vector <- rbind(my_final_vector, get_lex_variety(x))
}
write.csv(my_final_vector,"../temp.csv")
setwd("~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/corpus")
my_folder <- "~/Dropbox/ClassroomSlides-BothCourses/LING410X/22FEB2018Tutorial/corpus"
file.names <- dir(my_folder, pattern = "\\.txt")
my_final_output <- c()
for (f in file.names) {
x <- get_words_vector(f)
my_final_output <- rbind(my_final_vector, get_lex_variety(x))
}
file.names <- dir(my_folder, pattern = "\\.txt")
my_final_output <- c()
for (f in file.names) {
x <- get_words_vector(f)
my_final_output <- rbind(my_final_vector, get_lex_variety(x))
}
result <- getKwic(wordsvector, "gutenberg",3)
result
write.csv(result,"../temp2.csv")
text6words <- get_words_vector("text6.txt")
text5words <- get_words_vector("text5.txt")
text650 <- get_ngrams(text6words,3,50)
text550 <- get_ngrams(text5words,3,50)
text650
text550
names(text550)
text550["ngrams"]
intersect(text550["ngrams"],text650["ngrams"])
text550 <- get_ngrams(text5words,1,50)
text650 <- get_ngrams(text6words,1,50)
intersect(text550["ngrams"],text650["ngrams"])
text550["ngrams"]
unlist(text550$ngrams)
unlist(text750$ngrams)
unlist(text650$ngrams)
intersect(unlist(text550$ngrams),unlist(text650$ngrams))
intersect(unlist(text550$ngrams),unlist(text650$ngrams))
text6words <- get_words_vector("text6.txt")
text5words <- get_words_vector("text5.txt")
text650 <- get_ngrams(text6words,3,50)
text550 <- get_ngrams(text5words,3,50)
intersect(unlist(text550$ngrams),unlist(text650$ngrams))
